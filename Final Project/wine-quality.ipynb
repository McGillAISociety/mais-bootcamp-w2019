{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21434d00198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAF3CAYAAADtkpxQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFMNJREFUeJzt3Xvw5XV93/HXG1aCUIxYtqISu9qxzDjWFF2tDaOmEq3GW2PR6hRrNRnaTmOJTUJ1nGnSzmSmQ0wnbdImQ/A6GkwCYtWxRnLxEi/YBWlF0ZoqIis/WWrwglolvPvH72yzbHH358I579/l8Zj5zbn8zp7Pe84w7HO/3+/5fqu7AwDAah03PQAAwE4kwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAG7JoeYCNOO+203rNnz/QYAABHdfXVV9/a3buP9rotEWF79uzJvn37pscAADiqqvrCRl5ndyQAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADtsQFvAGAnePCCy/M2tpaTj/99Fx00UXT4yyNCAMANpW1tbXs379/eoylszsSAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAYsLcKq6nVVdUtVXXfIc79cVZ+uqv9RVVdU1f2XtT4AwGa2zC1hb0jy9MOeuzLJo7r70Un+Z5JXLXF9AIBNa9ey3ri7P1BVew577r2HPPxoknOXtT4AsDG/dN7m+uv4K7d8df127eZNN9ur33zZvfZek8eEvSzJfx1cHwBgzEiEVdWrk9yR5C1HeM35VbWvqvYdOHBgdcMBAKzAyiOsql6S5FlJ/mF39/d6XXdf3N17u3vv7t27VzcgAMAKLO2YsLtTVU9P8q+SPLm7v7nKtQEANpNlnqLi0iQfSXJmVd1UVT+Z5NeTnJLkyqq6tqp+c1nrAwBsZsv8duSL7ubp1y5rPQCArcQZ8wEABogwAIABIgwAYIAIAwAYsNJTVADAVnPhhRdmbW0tp59+ei666KLpcdhGRBgAHMHa2lr2798/PQbbkN2RAAADbAkDADaVE48/7i6325UIA2BT+fWffef0CHdx2623/7/bzTbbT//Ks6dHWIqz/vIp0yOsxPZOTACATUqEAQAMEGEAAAMcEwYAR3DyCfe7yy3cW0QYABzB2X/tedMjsE3ZHQkAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA1w7EmALufDCC7O2tpbTTz89F1100fQ4wD0gwgC2kLW1tezfv396DOBeYHckAMAAEQYAMMDuSIAjeP+Tnjw9wl18a9fxSVW+ddNNm262J3/g/dMjwJZiSxgAwABbwtg2fGsMgK1EhLFt+NYYO8H9u+9yC2xdImxJbJUBluG8P79zegTgXiLClsRWGQDgSByYDwAwQIQBAAwQYQAAAxwTxjG78d/+jekR7uKOrzwgya7c8ZUvbLrZHvqvPzE9AgCbjC1hAAADlhZhVfW6qrqlqq475LkHVNWVVfXZxe2py1ofAGAzW+aWsDckefphz70yyR929yOS/OHiMQDAjrO0COvuDyT5ymFPPzfJGxf335jk7y1rfQCAzWzVx4Q9sLtvTpLF7V9Z8foAAJvCpv12ZFWdn+T8JHnoQx86PA1wd1yeC+DYrTrCvlxVD+rum6vqQUlu+V4v7O6Lk1ycJHv37j3qlWof+/NvuvemvBeccuvXc3ySG2/9+qab7epf/kfTIyzFaSfemeSOxS2r4PJcAMdu1RH2jiQvSfLvFrf/ZcXrs4393KNvmx5h6c7+tbOnR7iLE247IcfluHzxti9uutk+9PIPTY8AcETLPEXFpUk+kuTMqrqpqn4y6/H11Kr6bJKnLh4DAOw4S9sS1t0v+h6/OmdZawIAbBWb9sB8YPPrkzp35s70SUc9bBOAw4gw4Jh99+zvTo8AsGW5diQAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAAOcrHVJ7jzh5LvcAgAcSoQtye2PeNr0CADAJmZ3JADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRiKsql5RVZ+squuq6tKqOnFiDgCAKSuPsKp6SJJ/kWRvdz8qyfFJXrjqOQAAJk3tjtyV5L5VtSvJSUm+NDQHAMCIlUdYd+9P8pokNya5OclXu/u9q54DAGDSxO7IU5M8N8nDkjw4yclVdd7dvO78qtpXVfsOHDiw6jEBAJZqYnfkjyX5fHcf6O7vJnlbkh85/EXdfXF37+3uvbt37175kAAAyzQRYTcmeUJVnVRVleScJNcPzAEAMGbimLCrklyW5Jokn1jMcPGq5wAAmLRrYtHu/oUkvzCxNgDAZuCM+QAAA0QYAMAAEQYAMECEAQAMEGEAAANEGADAABEGADBAhAEADBBhAAADRBgAwAARBgAwQIQBAAwQYQAAA0QYAMCAXUf6ZVV9Iknf3a+SdHc/eilTAQBsc0eMsCTPWskUAAA7zBEjrLu/cPB+VT0wyeMWDz/W3bcsczAAgO1sQ8eEVdULknwsyfOTvCDJVVV17jIHAwDYzo62O/KgVyd53MGtX1W1O8kfJLlsWYMBAGxnG/125HGH7X7839/HnwUA4DAb3RL2nqr6/SSXLh7/gyTvXs5IAADb34YirLt/vqr+fpKzs356iou7+4qlTgYAsI1tdEtYuvvyJJcvcRYAgB1jo9+OfF5VfbaqvlpVX6uqr1fV15Y9HADAdrXRLWEXJXl2d1+/zGEAAHaKjX7D8csCDADg3nO0a0c+b3F3X1X9TpK3J/k/B3/f3W9b4mwAANvW0XZHPvuQ+99M8rRDHncSEQYAcAyOdu3Il65qEACAnWSj3448o6quqKpbqurLVXV5VZ2x7OEAALarjR6Y//ok70jy4CQPSfLOxXMAAByDjUbY7u5+fXffsfh5Q5LdS5wLAGBb22iE3VpV51XV8Yuf87J+EW8AAI7BRiPsZUlekGQtyc1Jzl08BwDAMdjoBbxvTPKcJc8CALBjbPTbkW+sqvsf8vjUqnrd8sYCANjeNro78tHdfdvBB939Z0nOWs5IAADb30Yj7LiqOvXgg6p6QDZ+8W8AAA6z0ZD6lSQfrqrLFo+fn+SXljMSAMD2t9ED899UVfuSPCVJJXled39qqZMBAGxjR4ywxW7Hg9aS/Pahv+vurxzLoouD/C9J8qisXwj8Zd39kWN5LwCArehoW8Kuznok1eJxL25rcf/hx7juf0jynu4+t6pOSHLSMb4PAMCWdMQI6+6HHby/2Cr2iCQn3pMFq+p+SZ6U5B8v1vhOku/ck/cEANhqNnRMWFX9VJILkpyR5NokT0jy4STnHMOaD09yIMnrq+qHs7617YLuvv0Y3gsAYEva6CkqLkjyuCRf6O6/k/VzhN16jGvuSvKYJL/R3WcluT3JKw9/UVWdX1X7qmrfgQMHjnEpAIDNaaMR9u3u/naSVNUPdPenk5x5jGvelOSm7r5q8fiyrEfZXXT3xd29t7v37t69+xiXAgDYnDZ6nrCbFt9ofHuSK6vqz5J86VgW7O61qvpiVZ3Z3Z/J+i5Np7sAAHaUjZ4n7CcWd3+xqv44yQ8mec89WPflSd6y+Gbk55K89B68FwDAlvN9X3qou99/Txft7muT7L2n7wMAsFVt9JgwAADuRSIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAFjEVZVx1fVx6vqXVMzAABMmdwSdkGS6wfXBwAYMxJhVXVGkmcmuWRifQCAaVNbwn41yYVJ7vxeL6iq86tqX1XtO3DgwOomAwBYgZVHWFU9K8kt3X31kV7X3Rd3997u3rt79+4VTQcAsBoTW8LOTvKcqrohyVuTPKWq3jwwBwDAmJVHWHe/qrvP6O49SV6Y5I+6+7xVzwEAMMl5wgAABuyaXLy735fkfZMzAABMsCUMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAErj7Cq+qGq+uOqur6qPllVF6x6BgCAabsG1rwjyc929zVVdUqSq6vqyu7+1MAsAAAjVr4lrLtv7u5rFve/nuT6JA9Z9RwAAJNGjwmrqj1Jzkpy1eQcAACrNhZhVfWXklye5Ge6+2t38/vzq2pfVe07cODA6gcEAFiikQirqvtkPcDe0t1vu7vXdPfF3b23u/fu3r17tQMCACzZxLcjK8lrk1zf3f9+1esDAGwGE1vCzk7y4iRPqaprFz8/PjAHAMCYlZ+iorv/JEmtel0AgM3EGfMBAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGCDCAAAGiDAAgAEiDABggAgDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAaIMACAASIMAGCACAMAGDASYVX19Kr6TFX9aVW9cmIGAIBJK4+wqjo+yX9K8owkj0zyoqp65KrnAACYNLEl7PFJ/rS7P9fd30ny1iTPHZgDAGDMRIQ9JMkXD3l80+I5AIAdo7p7tQtWPT/J3+3un1o8fnGSx3f3yw973flJzl88PDPJZ1Y66L3jtCS3Tg+xw/jMV89nvno+89Xzma/eVv7M/2p37z7ai3atYpLD3JTkhw55fEaSLx3+ou6+OMnFqxpqGapqX3fvnZ5jJ/GZr57PfPV85qvnM1+9nfCZT+yO/G9JHlFVD6uqE5K8MMk7BuYAABiz8i1h3X1HVf10kt9PcnyS13X3J1c9BwDApIndkenudyd598TaK7ald6duUT7z1fOZr57PfPV85qu37T/zlR+YDwCAyxYBAIwQYUtQVSdW1ceq6r9X1Ser6t9Mz7RTVNXxVfXxqnrX9Cw7QVXdUFWfqKprq2rf9Dw7QVXdv6ouq6pPV9X1VfW3p2fazqrqzMV/3wd/vlZVPzM913ZXVa9Y/P15XVVdWlUnTs+0DHZHLkFVVZKTu/sbVXWfJH+S5ILu/ujwaNteVf3LJHuT3K+7nzU9z3ZXVTck2dvdW/VcPltOVb0xyQe7+5LFN8xP6u7bpufaCRaX3duf5G919xem59muquohWf9785Hd/a2q+t0k7+7uN8xOdu+zJWwJet03Fg/vs/hRu0tWVWckeWaSS6ZngWWoqvsleVKS1yZJd39HgK3UOUn+lwBbiV1J7ltVu5KclLs5n+h2IMKWZLFb7NoktyS5sruvmp5pB/jVJBcmuXN6kB2kk7y3qq5eXOWC5Xp4kgNJXr/Y7X5JVZ08PdQO8sIkl04Psd119/4kr0lyY5Kbk3y1u987O9VyiLAl6e4/7+6/mfUrAjy+qh41PdN2VlXPSnJLd189PcsOc3Z3PybJM5L886p60vRA29yuJI9J8hvdfVaS25O8cnaknWGx6/c5SX5vepbtrqpOTfLcJA9L8uAkJ1fVebNTLYcIW7LFroL3JXn68Cjb3dlJnrM4RumtSZ5SVW+eHWn76+4vLW5vSXJFksfPTrTt3ZTkpkO2rF+W9Shj+Z6R5Jru/vL0IDvAjyX5fHcf6O7vJnlbkh8ZnmkpRNgSVNXuqrr/4v59s/4f1Kdnp9reuvtV3X1Gd+/J+i6DP+rubfkvp82iqk6uqlMO3k/ytCTXzU61vXX3WpIvVtWZi6fOSfKpwZF2khfFrshVuTHJE6rqpMUX3c5Jcv3wTEsxcsb8HeBBSd64+CbNcUl+t7udMoHt5oFJrlj/f2R2Jfnt7n7P7Eg7wsuTvGWxe+xzSV46PM+2V1UnJXlqkn8yPctO0N1XVdVlSa5JckeSj2ebnj3fKSoAAAbYHQkAMECEAQAMEGEAAANEGADAABEGADBAhAE7WlXtqarrFvf3VtV/XNz/0aralieIBDYH5wkDWOjufUn2LR7+aJJvJPnw2EDAtmZLGLBlVdWrq+ozVfUHVXVpVf1cVb2vqvYufn/a4lJWB7d4fbCqrln8/H9buRZbv95VVXuS/NMkr6iqa6vqiVX1+aq6z+J196uqGw4+BjgWtoQBW1JVPTbrl6g6K+v/L7smyZEu4H5Lkqd297er6hFZvwTN3rt7YXffUFW/meQb3f2axXrvS/LMJG9frHv54rp2AMfEljBgq3pikiu6+5vd/bUk7zjK6++T5Leq6hNJfi/JI7/P9S7JX1wi6KVJXv99/nmAu7AlDNjK7u66a3fkL/6BeeIhz78iyZeT/PDi99/+vhbq/tBil+aTkxzf3S5WDtwjtoQBW9UHkvxEVd23qk5J8uzF8zckeezi/rmHvP4Hk9zc3XcmeXGS44/y/l9Pcsphz70p67sxbQUD7jERBmxJ3X1Nkt9Jcm2Sy5N8cPGr1yT5Z1X14SSnHfJH/nOSl1TVR5P89SS3H2WJd2Y98q6tqicunntLklOzHmIA90h1393WfICtpap+MYccSL+kNc5N8tzufvGy1gB2DseEAWxAVf1akmck+fHpWYDtwZYwAIABjgkDABggwgAABogwAIABIgwAYIAIAwAYIMIAAAb8X0ziVwX3SOMhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#try to visualize each features relevance with quality score\n",
    "import seaborn as sns\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(x = 'quality', y = 'alcohol', data = wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [2,6,9] #Since max quality score is 8 and min quality score is 3, devide them reseasonably with the boundary of 6\n",
    "quality_labels = ['bad', 'good']\n",
    "wine['quality'] = pd.cut(wine['quality'], bins = bins, labels = quality_labels, include_lowest = True)\n",
    "\n",
    "label_quality = LabelEncoder()\n",
    "wine['quality'] = label_quality.fit_transform(wine['quality']) #assign \"bad\" 0 and \"good\" 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1382\n",
       "1     217\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "X = wine.drop('quality', axis = 1)\n",
    "y = wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 50)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27870438 0.16788613 0.14124353 0.11916465]\n",
      "[31.32154879 24.30965178 22.29747104 20.48071223]\n"
     ]
    }
   ],
   "source": [
    "#PCA\n",
    "pca = PCA(n_components=4) ##choose four to keep above 10% variance; supported by studying the graph of each feature (citric acid, vol. acid, sulphate, alc.)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       287\n",
      "           1       0.69      0.61      0.65        33\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       320\n",
      "   macro avg       0.82      0.79      0.80       320\n",
      "weighted avg       0.93      0.93      0.93       320\n",
      "\n",
      "[[278   9]\n",
      " [ 13  20]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8960209325215163"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "rfc = RandomForestClassifier(n_estimators=35)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "print(classification_report(y_test, pred_rfc))\n",
    "print(confusion_matrix(y_test, pred_rfc))\n",
    "#Cross validation with rfc\n",
    "rfc_eval = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       287\n",
      "           1       0.57      0.39      0.46        33\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       320\n",
      "   macro avg       0.75      0.68      0.71       320\n",
      "weighted avg       0.89      0.91      0.90       320\n",
      "\n",
      "[[277  10]\n",
      " [ 20  13]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.889056491485076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest_PCA\n",
    "rfc = RandomForestClassifier(n_estimators=35)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "pred_rfc = rfc.predict(X_test_pca)\n",
    "print(classification_report(y_test, pred_rfc))\n",
    "print(confusion_matrix(y_test, pred_rfc))\n",
    "#Cross validation with rfc_pca\n",
    "rfc_eval = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       287\n",
      "           1       0.40      0.76      0.52        33\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       320\n",
      "   macro avg       0.68      0.81      0.72       320\n",
      "weighted avg       0.91      0.86      0.87       320\n",
      "\n",
      "[[249  38]\n",
      " [  8  25]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent\n",
    "sgd = SGDClassifier(penalty=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "pred_sgd = sgd.predict(X_test)\n",
    "print(classification_report(y_test, pred_sgd))\n",
    "print(confusion_matrix(y_test, pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       287\n",
      "           1       0.25      0.45      0.32        33\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       320\n",
      "   macro avg       0.59      0.65      0.60       320\n",
      "weighted avg       0.86      0.80      0.82       320\n",
      "\n",
      "[[241  46]\n",
      " [ 18  15]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent_PCA\n",
    "sgd = SGDClassifier(penalty=None)\n",
    "sgd.fit(X_train_pca, y_train)\n",
    "pred_sgd = sgd.predict(X_test_pca)\n",
    "print(classification_report(y_test, pred_sgd))\n",
    "print(confusion_matrix(y_test, pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.3, 'gamma': 1.3, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding best parameters for SVC model\n",
    "svc = SVC()\n",
    "param = {\n",
    "    'C': [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n",
    "    'kernel':['linear', 'rbf'],\n",
    "    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n",
    "}\n",
    "grid_svc = GridSearchCV(svc, param_grid=param, scoring='accuracy', cv=10)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "grid_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       287\n",
      "           1       0.88      0.45      0.60        33\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       320\n",
      "   macro avg       0.91      0.72      0.78       320\n",
      "weighted avg       0.93      0.94      0.93       320\n",
      "\n",
      "[[285   2]\n",
      " [ 18  15]]\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Classifier\n",
    "svc = SVC(C = 1.3, gamma =  1.3, kernel= 'rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "pred_svc = svc.predict(X_test)\n",
    "print(classification_report(y_test, pred_svc))\n",
    "print(confusion_matrix(y_test, pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.9, 'gamma': 0.8, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding best parameters for SVC model\n",
    "svc = SVC()\n",
    "param = {\n",
    "    'C': [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n",
    "    'kernel':['linear', 'rbf'],\n",
    "    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n",
    "}\n",
    "grid_svc = GridSearchCV(svc, param_grid=param, scoring='accuracy', cv=10)\n",
    "grid_svc.fit(X_train_pca, y_train)\n",
    "grid_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       287\n",
      "           1       0.64      0.48      0.55        33\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       320\n",
      "   macro avg       0.79      0.73      0.75       320\n",
      "weighted avg       0.91      0.92      0.91       320\n",
      "\n",
      "[[278   9]\n",
      " [ 17  16]]\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Classifier_PCA\n",
    "svc_pca = SVC(C = 0.9, gamma =  0.8, kernel= 'rbf')\n",
    "svc.fit(X_train_pca, y_train)\n",
    "pred_svc = svc.predict(X_test_pca)\n",
    "print(classification_report(y_test, pred_svc))\n",
    "print(confusion_matrix(y_test, pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8514936405115059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross validation with sgd\n",
    "rfc_eval = cross_val_score(estimator = sgd, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896014780946713"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross validation with svc\n",
    "rfc_eval = cross_val_score(estimator = svc, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MAIS-202)",
   "language": "python",
   "name": ".mais-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
