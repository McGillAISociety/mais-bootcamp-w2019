{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [2,6,9] #Since max quality score is 8 and min quality score is 3, devide them reseasonably with the boundary of 6\n",
    "quality_labels = ['bad', 'good']\n",
    "wine['quality'] = pd.cut(wine['quality'], bins = bins, labels = quality_labels, include_lowest = True)\n",
    "\n",
    "label_quality = LabelEncoder()\n",
    "wine['quality'] = label_quality.fit_transform(wine['quality']) #assign \"bad\" 0 and \"good\" 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1382\n",
       "1     217\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "X = wine.drop('quality', axis = 1)\n",
    "y = wine['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "pca = PCA(n_components=\"mle\")\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94       273\n",
      "           1       0.68      0.45      0.54        47\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       320\n",
      "   macro avg       0.79      0.71      0.74       320\n",
      "weighted avg       0.88      0.89      0.88       320\n",
      "\n",
      "[[263  10]\n",
      " [ 26  21]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9147945374015748"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "print(classification_report(y_test, pred_rfc))\n",
    "print(confusion_matrix(y_test, pred_rfc))\n",
    "#Cross validation with rfc\n",
    "rfc_eval = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       273\n",
      "           1       0.79      0.23      0.36        47\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       320\n",
      "   macro avg       0.83      0.61      0.65       320\n",
      "weighted avg       0.87      0.88      0.85       320\n",
      "\n",
      "[[270   3]\n",
      " [ 36  11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9140194389763779"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest_PCA\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "pred_rfc = rfc.predict(X_test_pca)\n",
    "print(classification_report(y_test, pred_rfc))\n",
    "print(confusion_matrix(y_test, pred_rfc))\n",
    "#Cross validation with rfc_pca\n",
    "rfc_eval = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       273\n",
      "           1       0.46      0.38      0.42        47\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       320\n",
      "   macro avg       0.68      0.65      0.66       320\n",
      "weighted avg       0.83      0.84      0.84       320\n",
      "\n",
      "[[252  21]\n",
      " [ 29  18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent\n",
    "sgd = SGDClassifier(penalty=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "pred_sgd = sgd.predict(X_test)\n",
    "print(classification_report(y_test, pred_sgd))\n",
    "print(confusion_matrix(y_test, pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       273\n",
      "           1       0.33      0.30      0.31        47\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       320\n",
      "   macro avg       0.61      0.60      0.60       320\n",
      "weighted avg       0.80      0.81      0.80       320\n",
      "\n",
      "[[245  28]\n",
      " [ 33  14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsofr\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stochastic Gradient Descent_PCA\n",
    "sgd = SGDClassifier(penalty=None)\n",
    "sgd.fit(X_train_pca, y_train)\n",
    "pred_sgd = sgd.predict(X_test_pca)\n",
    "print(classification_report(y_test, pred_sgd))\n",
    "print(confusion_matrix(y_test, pred_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding best parameters for SVC model\n",
    "svc = SVC()\n",
    "param = {\n",
    "    'C': [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n",
    "    'kernel':['linear', 'rbf'],\n",
    "    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n",
    "}\n",
    "grid_svc = GridSearchCV(svc, param_grid=param, scoring='accuracy', cv=10)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "grid_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       273\n",
      "           1       0.89      0.34      0.49        47\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       320\n",
      "   macro avg       0.89      0.67      0.72       320\n",
      "weighted avg       0.90      0.90      0.88       320\n",
      "\n",
      "[[271   2]\n",
      " [ 31  16]]\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Classifier\n",
    "svc = SVC(C = 1.2, gamma =  0.9, kernel= 'rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "pred_svc = svc.predict(X_test)\n",
    "print(classification_report(y_test, pred_svc))\n",
    "print(confusion_matrix(y_test, pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding best parameters for SVC model\n",
    "svc = SVC()\n",
    "param = {\n",
    "    'C': [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n",
    "    'kernel':['linear', 'rbf'],\n",
    "    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n",
    "}\n",
    "grid_svc = GridSearchCV(svc, param_grid=param, scoring='accuracy', cv=10)\n",
    "grid_svc.fit(X_train_pca, y_train)\n",
    "grid_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       273\n",
      "           1       0.82      0.19      0.31        47\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       320\n",
      "   macro avg       0.85      0.59      0.62       320\n",
      "weighted avg       0.87      0.88      0.84       320\n",
      "\n",
      "[[271   2]\n",
      " [ 38   9]]\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Classifier_PCA\n",
    "svc_pca = SVC(C = 1.4, gamma =  0.8, kernel= 'rbf')\n",
    "svc.fit(X_train_pca, y_train)\n",
    "pred_svc = svc.predict(X_test_pca)\n",
    "print(classification_report(y_test, pred_svc))\n",
    "print(confusion_matrix(y_test, pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation with sgd\n",
    "rfc_eval = cross_val_score(estimator = sgd, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation with svc\n",
    "rfc_eval = cross_val_score(estimator = svc, X = X_train, y = y_train, cv = 10)\n",
    "rfc_eval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MAIS-202)",
   "language": "python",
   "name": ".mais-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
