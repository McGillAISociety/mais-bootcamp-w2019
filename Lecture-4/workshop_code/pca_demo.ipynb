{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "for warning in (FutureWarning, np.ComplexWarning):\n",
    "    warnings.simplefilter(action='ignore', category=warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix most errors, try running the following command in bash: `pip install --upgrade numpy sklearn scikit-image matplotlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load face data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using face data from AT&T Labs Cambridge; the data consists of pictures of 40 different subjects, each under 10 different poses. Each image is grayscale and $112 \\times 92$ pixels, but we will downsize them to $56 \\times 46$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_faces = []\n",
    "for subject_number in range(1, 41):\n",
    "    for image_number in range(1, 11):\n",
    "        path = 'data/orl_faces/s{0}/{1}.jpg'.format(subject_number, image_number)\n",
    "        large_image = 256 - imread(path)\n",
    "        shape = large_image.shape\n",
    "        small_image = resize(large_image, (shape[0] / 2, shape[1] / 2), mode='constant', anti_aliasing=True)\n",
    "        all_faces.append(small_image / np.max(small_image))\n",
    "all_faces = np.array(all_faces)\n",
    "\n",
    "print(\"Total number of faces: {0}\".format(len(all_faces)))\n",
    "print(\"Size of each image: {0}\".format(all_faces[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a few faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.choice(len(all_faces), size=4):\n",
    "    plt.imshow(all_faces[i], cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unravel the data into vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 2D grid of $56 \\times 46$ pixels, but PCA operates on vectors. So, we will unravel each image into a vector of length $56 \\cdot 46 = 2576$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([face.ravel() for face in all_faces])\n",
    "print(\"Size of each vector: {0}\".format(X[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center the data and find eigenvalues of the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will find the eigenvalues of the centered covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_average_row = np.average(X, axis=0)\n",
    "X_bar = X - X_average_row\n",
    "sigma = X_bar.T.dot(X_bar)\n",
    "\n",
    "eigenvalues, _ = np.linalg.eig(sigma)\n",
    "\n",
    "plt.plot(np.arange(len(eigenvalues)), eigenvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa, most eigenvalues are really small! Let's zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(100), eigenvalues[:100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the eigenvalues die off quickly after the 50th or so. Let's do PCA onto 50 components, then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform PCA and view reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(X)\n",
    "\n",
    "X_pca = pca.transform(X)\n",
    "print(\"Shape of data before PCA: {0}\".format(X.shape))\n",
    "print(\"Shape of data after PCA: {0}\".format(X_pca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll tranform our compressed data back into the original, larger space in order to view the reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reconstructed = pca.inverse_transform(X_pca)\n",
    "print(\"Shape of data after reconstruction: {0}\".format(X_reconstructed.shape))\n",
    "for i in np.random.choice(len(all_faces), size=4):\n",
    "    original = X[i].reshape(56, 46)\n",
    "    reconstructed = X_reconstructed[i].reshape(56, 46)\n",
    "    divider = np.ones((original.shape[0], 1))\n",
    "    plt.imshow(np.concatenate((original, divider, reconstructed), axis=1), cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try different numbers of principle components. What do you think will happen when we increase the number of components? Decrease the number of components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_components in (300, 5):\n",
    "    \n",
    "    print(\"Performing PCA on n_components = {0} ...\".format(n_components))\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X)\n",
    "    X_reconstructed = pca.inverse_transform(pca.transform(X))\n",
    "    \n",
    "    for i in np.random.choice(len(all_faces), size=4):\n",
    "        original = X[i].reshape(56, 46)\n",
    "        reconstructed = X_reconstructed[i].reshape(56, 46)\n",
    "        divider = np.ones((original.shape[0], 1))\n",
    "        plt.imshow(np.concatenate((original, divider, reconstructed), axis=1), cmap='Greys')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
